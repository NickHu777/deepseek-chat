# app/services/vector_service.py
"""
å‘é‡æœåŠ¡ï¼šè´Ÿè´£æ–‡æœ¬å‘é‡åŒ–å’Œå‘é‡æœç´¢
"""
import logging
import hashlib
from typing import List, Dict, Any, Optional
import numpy as np

from app.config import settings

logger = logging.getLogger(__name__)


class VectorService:
    """å‘é‡æœåŠ¡"""

    def __init__(self):
        """åˆå§‹åŒ–å‘é‡æœåŠ¡ï¼ˆå»¶è¿ŸåŠ è½½æ¨¡å‹ï¼‰"""
        self.dimension = settings.EMBEDDING_DIMENSION
        self.model = None
        self._model_load_attempted = False  # æ˜¯å¦å·²å°è¯•åŠ è½½
        self._use_lazy_loading = True  # ä½¿ç”¨å»¶è¿ŸåŠ è½½

        logger.info(f"âœ… å‘é‡æœåŠ¡åˆå§‹åŒ–å®Œæˆ (ç»´åº¦: {self.dimension}, å»¶è¿ŸåŠ è½½æ¨¡å¼)")

    def _try_load_model(self, force_reload: bool = False):
        """å°è¯•åŠ è½½å‘é‡æ¨¡å‹ï¼ˆå¸¦è¶…æ—¶å’Œå¿«é€Ÿå¤±è´¥ï¼‰"""
        # å¦‚æœå·²ç»å°è¯•è¿‡ä¸”ä¸å¼ºåˆ¶é‡æ–°åŠ è½½ï¼Œç›´æ¥è¿”å›
        if self._model_load_attempted and not force_reload:
            return
        
        self._model_load_attempted = True
        
        try:
            logger.info(f"â³ å¼€å§‹åŠ è½½å‘é‡æ¨¡å‹: {settings.VECTOR_MODEL}")
            
            # æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼Œå…è®¸è·³è¿‡æ¨¡å‹åŠ è½½
            import os
            if os.getenv("SKIP_VECTOR_MODEL", "false").lower() == "true":
                logger.info("ğŸš« ç¯å¢ƒå˜é‡ SKIP_VECTOR_MODEL=trueï¼Œè·³è¿‡æ¨¡å‹åŠ è½½")
                self.model = None
                return

            # å°è¯•å¯¼å…¥ sentence-transformers
            try:
                from sentence_transformers import SentenceTransformer
                import socket
                
                # è®¾ç½®è¶…æ—¶ï¼ˆé¿å…é•¿æ—¶é—´ç­‰å¾…ï¼‰
                socket.setdefaulttimeout(5)  # 5ç§’è¶…æ—¶
                
                try:
                    # ä½¿ç”¨æœ¬åœ°ç¼“å­˜ä¼˜å…ˆ
                    import os
                    cache_folder = os.path.expanduser("~/.cache/huggingface/hub")
                    
                    logger.info(f"ğŸ“¥ åŠ è½½æ¨¡å‹ï¼ˆæœ¬åœ°ç¼“å­˜ä¼˜å…ˆï¼‰: {settings.VECTOR_MODEL}")
                    
                    # åŠ è½½æ¨¡å‹ï¼ˆä¼šå…ˆæ£€æŸ¥æœ¬åœ°ç¼“å­˜ï¼‰
                    self.model = SentenceTransformer(
                        settings.VECTOR_MODEL,
                        cache_folder=cache_folder
                    )
                    
                    logger.info("âœ… å‘é‡æ¨¡å‹åŠ è½½æˆåŠŸ")

                    # éªŒè¯æ¨¡å‹ç»´åº¦
                    test_embedding = self.model.encode("test")
                    actual_dim = len(test_embedding)
                    
                    if actual_dim != self.dimension:
                        logger.warning(f"âš ï¸  é…ç½®ç»´åº¦({self.dimension})ä¸æ¨¡å‹å®é™…ç»´åº¦({actual_dim})ä¸åŒ¹é…")
                        self.dimension = actual_dim  # è‡ªåŠ¨æ›´æ–°ç»´åº¦
                        logger.info(f"âœ… å·²è‡ªåŠ¨æ›´æ–°å‘é‡ç»´åº¦ä¸º {actual_dim}")

                except Exception as e:
                    error_msg = str(e)
                    if "Max retries" in error_msg or "Network is unreachable" in error_msg:
                        logger.warning(f"âš ï¸  ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œæ— æ³•ä¸‹è½½æ¨¡å‹ï¼ˆå°†ä½¿ç”¨å ä½å‘é‡ï¼‰")
                        logger.info("ğŸ’¡ æç¤ºï¼šå¦‚éœ€ä½¿ç”¨çœŸå®å‘é‡ï¼Œè¯·ç¡®ä¿ç½‘ç»œç•…é€šæˆ–è®¾ç½® HF_ENDPOINT é•œåƒ")
                    else:
                        logger.error(f"âŒ åŠ è½½å‘é‡æ¨¡å‹å¤±è´¥: {error_msg}")
                    
                    self.model = None
                finally:
                    # æ¢å¤é»˜è®¤è¶…æ—¶
                    socket.setdefaulttimeout(None)

            except ImportError as e:
                logger.warning(f"âš ï¸  æœªå®‰è£… sentence-transformers: {e}")
                logger.info("ğŸ’¡ å®‰è£…å‘½ä»¤: pip install sentence-transformers")
                self.model = None

        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å‘é‡æ¨¡å‹æ—¶å‡ºé”™: {e}")
            self.model = None

    def get_embedding(self, text: str) -> List[float]:
        """è·å–å•ä¸ªæ–‡æœ¬çš„å‘é‡è¡¨ç¤ºï¼ˆé¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½æ¨¡å‹ï¼‰"""
        try:
            if not text or not text.strip():
                logger.debug("æ–‡æœ¬ä¸ºç©ºï¼Œè¿”å›é›¶å‘é‡")
                return self._get_zero_vector()

            # å»¶è¿ŸåŠ è½½ï¼šé¦–æ¬¡ä½¿ç”¨æ—¶æ‰åŠ è½½æ¨¡å‹
            if self._use_lazy_loading and not self._model_load_attempted:
                logger.info("ğŸ”„ é¦–æ¬¡è°ƒç”¨å‘é‡æœåŠ¡ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
                self._try_load_model()

            # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œä½¿ç”¨çœŸå®æ¨¡å‹
            if self.model is not None:
                try:
                    embedding = self.model.encode(text)
                    return embedding.tolist()
                except Exception as e:
                    logger.error(f"ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå‘é‡å¤±è´¥ï¼Œä½¿ç”¨ä¼ªéšæœºå‘é‡æ›¿ä»£: {e}")
                    return self._get_random_vector(text)

            # å¦åˆ™è¿”å›ä¼ªéšæœºå‘é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            logger.debug("å‘é‡æ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨ä¼ªéšæœºå‘é‡")
            return self._get_random_vector(text)

        except Exception as e:
            logger.error(f"ç”Ÿæˆå‘é‡å¤±è´¥: {e}")
            return self._get_zero_vector()

    def get_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡è·å–å‘é‡ï¼ˆæ›´é«˜æ•ˆï¼Œé¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½æ¨¡å‹ï¼‰"""
        try:
            if not texts:
                return []

            # å»¶è¿ŸåŠ è½½ï¼šé¦–æ¬¡ä½¿ç”¨æ—¶æ‰åŠ è½½æ¨¡å‹
            if self._use_lazy_loading and not self._model_load_attempted:
                logger.info("ğŸ”„ é¦–æ¬¡æ‰¹é‡è°ƒç”¨å‘é‡æœåŠ¡ï¼Œå¼€å§‹åŠ è½½æ¨¡å‹...")
                self._try_load_model()

            # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œä½¿ç”¨çœŸå®æ¨¡å‹æ‰¹é‡å¤„ç†
            if self.model is not None:
                try:
                    embeddings = self.model.encode(texts)
                    return embeddings.tolist()
                except Exception as e:
                    logger.error(f"ä½¿ç”¨æ¨¡å‹æ‰¹é‡ç”Ÿæˆå‘é‡å¤±è´¥ï¼Œä½¿ç”¨é€æ¡ç”Ÿæˆæ›¿ä»£: {e}")
                    # é™çº§åˆ°é€æ¡ç”Ÿæˆ
                    pass

            # é€æ¡ç”Ÿæˆå‘é‡ï¼ˆæ”¯æŒæ¨¡å‹å’Œéšæœºå‘é‡ï¼‰
            embeddings = []
            for text in texts:
                embedding = self.get_embedding(text)
                embeddings.append(embedding)

            return embeddings

        except Exception as e:
            logger.error(f"æ‰¹é‡ç”Ÿæˆå‘é‡å¤±è´¥: {e}")
            return [self._get_zero_vector() for _ in range(len(texts))]

    def calculate_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            a = np.array(vec1)
            b = np.array(vec2)

            # è®¡ç®—ç‚¹ç§¯
            dot_product = np.dot(a, b)

            # è®¡ç®—æ¨¡é•¿
            norm_a = np.linalg.norm(a)
            norm_b = np.linalg.norm(b)

            # é¿å…é™¤ä»¥é›¶
            if norm_a == 0 or norm_b == 0:
                return 0.0

            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = dot_product / (norm_a * norm_b)

            # ç¡®ä¿åœ¨[-1, 1]èŒƒå›´å†…
            similarity = max(-1.0, min(1.0, similarity))

            return float(similarity)

        except Exception as e:
            logger.error(f"è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0

    def search_similar(
            self,
            db,
            query: str,
            limit: int = None,
            threshold: float = None,
            collection_name: str = "documents"
    ) -> List:
        """
        æœç´¢ç›¸ä¼¼çš„æ–‡æ¡£å—

        Args:
            db: æ•°æ®åº“ä¼šè¯
            query: æŸ¥è¯¢æ–‡æœ¬
            limit: è¿”å›ç»“æœæ•°é‡
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            collection_name: é›†åˆåç§°

        Returns:
            List[DocumentSearchResult]: æœç´¢ç»“æœåˆ—è¡¨
        """
        if limit is None:
            limit = settings.SEARCH_LIMIT
        if threshold is None:
            threshold = settings.SIMILARITY_THRESHOLD

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.get_embedding(query)

        logger.info(f"å‘é‡æœç´¢: query='{query[:50]}...', limit={limit}, threshold={threshold}")

        try:
            from app.models.document import DocumentChunk, Document
            from app.schemas.document import DocumentSearchResult
            
            # æŸ¥è¯¢æ‰€æœ‰æ–‡æ¡£åˆ†å—ï¼ˆæœªæ¥ä½¿ç”¨ pgvector ä¼˜åŒ–ï¼‰
            chunks = db.query(DocumentChunk).join(Document).filter(
                DocumentChunk.embedding.isnot(None)
            ).all()
            
            if not chunks:
                logger.warning("æ•°æ®åº“ä¸­æ²¡æœ‰å·²å‘é‡åŒ–çš„æ–‡æ¡£åˆ†å—")
                return []
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            results_with_scores = []
            for chunk in chunks:
                if chunk.embedding:
                    try:
                        similarity = self.cosine_similarity(query_embedding, chunk.embedding)
                        
                        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç»“æœ
                        if similarity >= threshold:
                            results_with_scores.append({
                                "chunk": chunk,
                                "similarity": float(similarity)
                            })
                    except Exception as e:
                        logger.debug(f"è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥ (chunk_id={chunk.id}): {e}")
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶é™åˆ¶æ•°é‡
            results_with_scores.sort(key=lambda x: x["similarity"], reverse=True)
            results_with_scores = results_with_scores[:limit]
            
            # è½¬æ¢ä¸ºå“åº”æ ¼å¼
            search_results = []
            for item in results_with_scores:
                chunk = item["chunk"]
                search_results.append(
                    DocumentSearchResult(
                        chunk_id=chunk.id,
                        chunk_text=chunk.chunk_text,
                        filename=chunk.document.filename,
                        document_id=chunk.document_id,
                        similarity=item["similarity"],
                        metadata=chunk.chunk_metadata or {}
                    )
                )
            
            logger.info(f"æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³ç»“æœ")
            return search_results

        except Exception as e:
            logger.error(f"å‘é‡æœç´¢å¤±è´¥: {e}", exc_info=True)
            return []

    def calculate_batch_similarities(
            self,
            query_vec: List[float],
            vectors: List[List[float]]
    ) -> List[float]:
        """æ‰¹é‡è®¡ç®—ç›¸ä¼¼åº¦"""
        try:
            if not vectors:
                return []

            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            query_np = np.array(query_vec)
            vectors_np = np.array(vectors)

            # æ‰¹é‡è®¡ç®—ç‚¹ç§¯
            dot_products = np.dot(vectors_np, query_np)

            # è®¡ç®—æŸ¥è¯¢å‘é‡çš„æ¨¡é•¿
            query_norm = np.linalg.norm(query_np)

            # è®¡ç®—æ‰€æœ‰å‘é‡çš„æ¨¡é•¿
            vectors_norms = np.linalg.norm(vectors_np, axis=1)

            # é¿å…é™¤ä»¥é›¶
            with np.errstate(divide='ignore', invalid='ignore'):
                similarities = dot_products / (vectors_norms * query_norm)
                similarities = np.nan_to_num(similarities, nan=0.0, posinf=0.0, neginf=0.0)

            # ç¡®ä¿åœ¨[-1, 1]èŒƒå›´å†…
            similarities = np.clip(similarities, -1.0, 1.0)

            return similarities.tolist()

        except Exception as e:
            logger.error(f"æ‰¹é‡è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return [0.0] * len(vectors)

    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        info = {
            "model_name": settings.VECTOR_MODEL,
            "dimension": self.dimension,
            "model_loaded": self.model is not None,
            "model_type": "sentence-transformers" if self.model is not None else "placeholder",
        }

        if self.model is not None:
            info.update({
                "model_device": str(getattr(self.model, 'device', 'unknown')),
                "model_max_length": getattr(self.model, 'max_seq_length', 'unknown'),
            })

        return info

    def _get_zero_vector(self) -> List[float]:
        """è·å–é›¶å‘é‡"""
        return [0.0] * self.dimension

    def _get_random_vector(self, text: str) -> List[float]:
        """è·å–ä¼ªéšæœºå‘é‡ï¼ˆåŸºäºæ–‡æœ¬å“ˆå¸Œï¼Œç”¨äºæµ‹è¯•ï¼‰"""
        try:
            # ä½¿ç”¨æ–‡æœ¬çš„å“ˆå¸Œå€¼ç”Ÿæˆå¯é‡å¤çš„"éšæœº"å‘é‡
            text_hash = hashlib.md5(text.encode()).hexdigest()
            seed = int(text_hash[:8], 16)

            # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
            np.random.seed(seed)

            # ç”Ÿæˆéšæœºå‘é‡
            vector = np.random.randn(self.dimension).tolist()

            # å½’ä¸€åŒ–åˆ°å•ä½é•¿åº¦
            norm = np.linalg.norm(vector)
            if norm > 0:
                vector = (np.array(vector) / norm).tolist()

            return vector

        except Exception as e:
            logger.error(f"ç”Ÿæˆéšæœºå‘é‡å¤±è´¥: {e}")
            return self._get_zero_vector()

    def normalize_vector(self, vector: List[float]) -> List[float]:
        """å½’ä¸€åŒ–å‘é‡åˆ°å•ä½é•¿åº¦"""
        try:
            vec_np = np.array(vector)
            norm = np.linalg.norm(vec_np)

            if norm == 0:
                return vector

            normalized = (vec_np / norm).tolist()
            return normalized

        except Exception as e:
            logger.error(f"å½’ä¸€åŒ–å‘é‡å¤±è´¥: {e}")
            return vector

    def is_model_loaded(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½"""
        return self.model is not None

    def reload_model(self, model_name: Optional[str] = None) -> bool:
        """é‡æ–°åŠ è½½æ¨¡å‹"""
        try:
            old_model = self.model

            if model_name:
                settings.VECTOR_MODEL = model_name

            logger.info(f"é‡æ–°åŠ è½½å‘é‡æ¨¡å‹: {settings.VECTOR_MODEL}")
            self.model = None

            # å°è¯•åŠ è½½æ–°æ¨¡å‹
            self._try_load_model()

            success = self.model is not None

            if success:
                logger.info("âœ… æ¨¡å‹é‡æ–°åŠ è½½æˆåŠŸ")
                if old_model:
                    # æ¸…ç†æ—§æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    del old_model
            else:
                logger.warning("âŒ æ¨¡å‹é‡æ–°åŠ è½½å¤±è´¥")

            return success

        except Exception as e:
            logger.error(f"é‡æ–°åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False


# åˆ›å»ºå…¨å±€å®ä¾‹
vector_service = VectorService()


# æ·»åŠ æ¨¡å—çº§åˆ«çš„ä¾¿æ·å‡½æ•°
def get_vector_service() -> VectorService:
    """è·å–å‘é‡æœåŠ¡å®ä¾‹"""
    return vector_service